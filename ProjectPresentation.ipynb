{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7b5af96",
   "metadata": {},
   "source": [
    "# Reinforcement Learning-Based Traffic Light Optimization\n",
    "\n",
    "### Group 5\n",
    "| #     | Name |\n",
    "|-------|---------------|\n",
    "|8965985|Pradeepti Kasam|\n",
    "|9027375|Khushbu Lad|\n",
    "|8944328|Akshata Madhav|\n",
    "|8914803|Rohit Totlani| \n",
    "|8964515|Neha Yadav|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de426b90",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This project aims to develop a reinforcement learning (RL) agent capable of optimizing traffic flow by managing a single traffic light at an intersection. The agent will learn to adjust the signal timing dynamically to reduce congestion and improve vehicle movement efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd7fd28",
   "metadata": {},
   "source": [
    "#### States\n",
    "The state represents the ***current condition*** of the ***traffic intersection***\n",
    "\n",
    "***NS*** : Sum of cars in the North-South direction.<br/>\n",
    "***EW***: Sum of cars in the East-West direction.<br/>\n",
    "***NS_array***: Array representing the number of cars in different positions in the North-South direction.<br/>\n",
    "***EW_array***: Array representing the number of cars in different positions in the East-West direction.<br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6516017",
   "metadata": {},
   "source": [
    "#### Actions\n",
    "Actions represent the choices available to the agent that controls the traffic lights\n",
    "\n",
    "***Action 0*** – Allow traffic to flow in the North-South (NS) direction (green light for NS, red light for EW). <br>\n",
    "***Action 1*** – Allow traffic to flow in the East-West (EW) direction (green light for EW, red light for NS)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee7e01",
   "metadata": {},
   "source": [
    "#### Discrete State Representation\n",
    "\n",
    "Given that the number of cars is kept between 0 and 5 for both directions (NS and EW), the state space is discrete with values ranging from 0 to 5 for both NS and EW.\n",
    "\n",
    "Discrete state can be a tuple (NS, EW) where both NS and EW are between 0 and 5:\n",
    "<br/>\n",
    "<br/>\n",
    "```state = (min(state[\"NS\"], 5), min(state[\"EW\"], 5))```\n",
    "\n",
    "#### State space\n",
    "For each intersection, there are 6 possible values (0 through 5) for both NS and EW, so the total number of possible discrete states is:\n",
    "\n",
    "State space: 6 (NS values) × 6 (EW values) = ***36 possible states***."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d393a9d1",
   "metadata": {},
   "source": [
    "#### State Action Diagram\n",
    "\n",
    "<img src=\"./StateActionDiagram.png\" alt=\"Alt text\" width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1c9386",
   "metadata": {},
   "source": [
    "#### Reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd96a8d",
   "metadata": {},
   "source": [
    "- The reward function encourages clearing vehicles from the intersection, i.e., minimizing traffic.\n",
    "<br/>\n",
    "<br/>\n",
    "```reward = cleared```\n",
    "<br/>\n",
    "<br/>\n",
    "- Every time, agent take an action, vehicles in last selected directions are cleared, ***the number of vehicles cleared from intersection becomes rewards***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf59b73",
   "metadata": {},
   "source": [
    "#### State / Value Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a16055",
   "metadata": {},
   "source": [
    "```state = (min(NS_count, 5), min(EW_count, 5))```\n",
    "\n",
    "##### Value Function\n",
    "\n",
    "Estimated future reward from a state or state-action pair\n",
    "<br/>\n",
    "<br/>\n",
    "```q_table = {(ns, ew): [0, 0]}``` \n",
    "\n",
    "Updated using Q-Function\n",
    "<br/>\n",
    "<br/>\n",
    "```Q(s, a) ← Q(s, a) + α * (r + γ * max(Q(s', a')) - Q(s, a))```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feeb544",
   "metadata": {},
   "source": [
    "#### Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8580a8b3",
   "metadata": {},
   "source": [
    "Following Greedy Policy\n",
    "\n",
    "```select_action(q_table, state, epsilon)```\n",
    "\n",
    "- With probability ε, choose a random action (exploration).\n",
    "- With probability 1−ε, choose best known action (exploitation):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e76934",
   "metadata": {},
   "source": [
    "#### Markov Decision Process (MDP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ca3896",
   "metadata": {},
   "source": [
    "- Simulation is a classic finite MDP\n",
    "- Next state only depends on current state and action, not on past steps.\n",
    "- It includes randomness in vehicle inflow (modeled by np.random.choice)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b09b221",
   "metadata": {},
   "source": [
    "#### Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5b0b36",
   "metadata": {},
   "source": [
    "- Although your current Q-learning algorithm uses table-based updates\n",
    "- Policy gradients or value gradients are used to update neural networks.<br/>\n",
    "<br/>\n",
    "```Q(s, a) ← Q(s, a) + α * (target - Q(s, a))```\n",
    "<br/><br/>\n",
    "- Here, temporal difference (TD) update\n",
    "- a form of gradient descent over Q-values using:\n",
    "    - α: learning rate (step size)\n",
    "    - target: reward + discounted future value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb7ea9f",
   "metadata": {},
   "source": [
    "## Code Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf9ad74",
   "metadata": {},
   "source": [
    "### Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aeb2f1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (25.0.1)\n",
      "Requirement already satisfied: streamlit in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (1.44.1)\n",
      "Requirement already satisfied: numpy in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: altair<6,>=4.0 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: packaging<25,>=20 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from streamlit) (24.1)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from streamlit) (2.2.2)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from streamlit) (10.4.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from streamlit) (5.29.4)\n",
      "Requirement already satisfied: pyarrow>=7.0 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from streamlit) (19.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.27 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from streamlit) (4.13.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: jinja2 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.34.1)\n",
      "Requirement already satisfied: colorama in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in d:\\conestoga\\2_cscn8020-rl\\cscn8020-rainforcement-learning\\venvcscn8020\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n"
     ]
    }
   ],
   "source": [
    "## Install necessary libraries\n",
    "# To install the required libraries, run the following commands in a separate cell:\n",
    "!python -m pip install --upgrade pip\n",
    "!pip install streamlit numpy matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25e8be3",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd8e3c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fadcfde",
   "metadata": {},
   "source": [
    "## Traffic Light Optimization using Q-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bf6795",
   "metadata": {},
   "source": [
    "#### Class : TrafficIntersection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c477fa",
   "metadata": {},
   "source": [
    "```cars_ns``` : the number of cars at different positions for the north-south (NS) <br/>\n",
    "```cars_ew``` : the number of cars at different positions for the east-west (EW) <br/>\n",
    "```inflow_prob``` : The probability that a new car will enter the intersection from either direction <br/>\n",
    "```total_cleared``` : The total number of cars cleared from the intersection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b306b9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Traffic Environment ---------------- #\n",
    "class TrafficIntersection:\n",
    "\n",
    "    # Initializes the intersection with default values for the number of cars and inflow probability.\n",
    "    def __init__(self, inflow_prob=0.5):\n",
    "        self.cars_ns = np.zeros(5, dtype=int) \n",
    "        self.cars_ew = np.zeros(5, dtype=int)\n",
    "        self.inflow_prob = inflow_prob\n",
    "        self.total_cleared = 0\n",
    "        \n",
    "    # Resets the environment (cars at the intersection) and returns the current state.\n",
    "    def reset(self):\n",
    "        self.cars_ns[:] = 0\n",
    "        self.cars_ew[:] = 0\n",
    "        self.total_cleared = 0\n",
    "        return self.get_state()\n",
    "\n",
    "    # Executes a step in the environment. \n",
    "    # It takes an action (0 for NS green light, 1 for EW green light), \n",
    "    # updates the state, car positions, and clears cars based on the action.\n",
    "    def step(self, action):\n",
    "        cleared = 0\n",
    "        if action == 0:\n",
    "            cleared = self.cars_ns[-1]\n",
    "            self.cars_ns[1:] = self.cars_ns[:-1]\n",
    "            self.cars_ns[0] = np.random.choice([0, 1], p=[1 - self.inflow_prob, self.inflow_prob])\n",
    "            self.cars_ew += np.random.choice([0, 1], size=5, p=[0.7, 0.3])\n",
    "        else:\n",
    "            cleared = self.cars_ew[-1]\n",
    "            self.cars_ew[1:] = self.cars_ew[:-1]\n",
    "            self.cars_ew[0] = np.random.choice([0, 1], p=[1 - self.inflow_prob, self.inflow_prob])\n",
    "            self.cars_ns += np.random.choice([0, 1], size=5, p=[0.7, 0.3])\n",
    "\n",
    "        self.cars_ns = np.clip(self.cars_ns, 0, 1)\n",
    "        self.cars_ew = np.clip(self.cars_ew, 0, 1)\n",
    "\n",
    "        self.total_cleared += cleared\n",
    "        reward = cleared\n",
    "        state = self.get_state()\n",
    "        return state, reward, reward > 0\n",
    "\n",
    "    # Returns the current state of the intersection\n",
    "    def get_state(self):\n",
    "        return {\n",
    "            \"NS\": self.cars_ns.sum(),\n",
    "            \"EW\": self.cars_ew.sum(),\n",
    "            \"NS_array\": self.cars_ns.copy(),\n",
    "            \"EW_array\": self.cars_ew.copy()\n",
    "        }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1330063e",
   "metadata": {},
   "source": [
    "#### Q-Learning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a4182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the state (number of cars in NS and EW directions) into a discrete representation suitable for Q-learning.\n",
    "def get_discrete_state(state):\n",
    "    return (min(state[\"NS\"], 5), min(state[\"EW\"], 5))\n",
    "\n",
    "# Chooses an action (0 or 1) based on the epsilon-greedy strategy. \n",
    "# It either selects a random action or the best action based on the Q-table.\n",
    "def select_action(q_table, state, epsilon):\n",
    "    if np.random.random() < epsilon:\n",
    "        return np.random.choice([0, 1])\n",
    "    return np.argmax(q_table[state])\n",
    "\n",
    "# Updates the Q-table using the Q-learning update rule, based on the current state, action taken, reward, and the next state.\n",
    "def update_q_table(q_table, state, action, reward, next_state, alpha, gamma):\n",
    "    old_value = q_table[state][action]\n",
    "    future_max = np.max(q_table[next_state])\n",
    "    new_value = old_value + alpha * (reward + gamma * future_max - old_value)\n",
    "    q_table[state][action] = new_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9046add3",
   "metadata": {},
   "source": [
    "#### Agent Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b95ab3",
   "metadata": {},
   "source": [
    "- Trains the agents using ***Q-learning*** for ```n_intersections``` intersections over ```episodes``` number of episodes.\n",
    "- For each intersection, a Q-table is initialized, and the traffic light action is taken according to the Q-learning policy.\n",
    "- The environment is updated, and the Q-table is updated based on the reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df2091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agents(n_intersections, episodes=500, alpha=0.1, gamma=0.9, epsilon=0.1):\n",
    "    q_tables = []\n",
    "    all_rewards = []\n",
    "    inflow_probs = np.linspace(0.3, 0.7, n_intersections)\n",
    "\n",
    "    for i in range(n_intersections):\n",
    "        q_table = {(ns, ew): [0, 0] for ns in range(6) for ew in range(6)}\n",
    "        rewards_per_episode = []\n",
    "        env = TrafficIntersection(inflow_prob=inflow_probs[i])\n",
    "\n",
    "        for ep in range(episodes):\n",
    "            state = get_discrete_state(env.reset())\n",
    "            total_reward = 0\n",
    "            for step in range(50):\n",
    "                action = select_action(q_table, state, epsilon)\n",
    "                next_state, reward, _ = env.step(action)\n",
    "                next_state = get_discrete_state(next_state)\n",
    "                update_q_table(q_table, state, action, reward, next_state, alpha, gamma)\n",
    "                state = next_state\n",
    "                total_reward += reward\n",
    "            rewards_per_episode.append(total_reward)\n",
    "\n",
    "        q_tables.append(q_table)\n",
    "        all_rewards.append(rewards_per_episode)\n",
    "\n",
    "    return q_tables, all_rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd14a927",
   "metadata": {},
   "source": [
    "#### Demo Agent logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cc2926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a visualization of the traffic intersection using matplotlib\n",
    "def draw_intersection(state, action, step, idx, countdown, highlight_clear):\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    ax.set_xlim(0, 10)\n",
    "    ax.set_ylim(0, 10)\n",
    "    ax.axis('off')\n",
    "    ax.set_facecolor(\"#2e2e2e\")\n",
    "    ax.add_patch(plt.Rectangle((0, 4.5), 10, 1, color=\"#444\"))\n",
    "    ax.add_patch(plt.Rectangle((4.5, 0), 1, 10, color=\"#444\"))\n",
    "    for i in range(0, 10, 1):\n",
    "        ax.plot([i, i + 0.5], [5.0, 5.0], color=\"white\", linewidth=1, linestyle=\"--\")\n",
    "        ax.plot([5.0, 5.0], [i, i + 0.5], color=\"white\", linewidth=1, linestyle=\"--\")\n",
    "    light_ns_color = \"green\" if action == 0 else \"red\"\n",
    "    light_ew_color = \"green\" if action == 1 else \"red\"\n",
    "    ax.add_patch(plt.Circle((5, 9), 0.4, color=light_ns_color))\n",
    "    ax.text(5, 8.3, f\"{countdown}s\", ha='center', va='center', fontsize=10, color='black', bbox=dict(facecolor='white', boxstyle='round,pad=0.2'))\n",
    "    ax.add_patch(plt.Circle((9, 5), 0.4, color=light_ew_color))\n",
    "    ax.text(8.2, 5, f\"{countdown}s\", ha='center', va='center', fontsize=10, color='black', bbox=dict(facecolor='white', boxstyle='round,pad=0.2'))\n",
    "\n",
    "    for i in range(5):\n",
    "        if state[\"NS_array\"][i]:\n",
    "            ax.add_patch(plt.Rectangle((4.6, 9 - i), 0.8, 0.5, color=\"red\", alpha=0.9))\n",
    "        if state[\"EW_array\"][i]:\n",
    "            ax.add_patch(plt.Rectangle((i, 4.6), 0.5, 0.8, color=\"blue\", alpha=0.9))\n",
    "\n",
    "    if highlight_clear:\n",
    "        ax.text(5, 5.2, \"+1\", ha='center', va='center', fontsize=14, color='lime', fontweight='bold')\n",
    "    ax.text(5, 1, \"S ↓\", ha='center', va='center', fontsize=9, color='white')\n",
    "    ax.text(5, 9.3, \"N ↑\", ha='center', va='center', fontsize=9, color='white')\n",
    "    ax.text(1.2, 5, \"W ←\", ha='center', va='center', fontsize=9, color='white')\n",
    "    ax.text(8.8, 5, \"E →\", ha='center', va='center', fontsize=9, color='white')\n",
    "    fig.text(0.5, 1.0, f\"Intersection {idx+1}\", ha='center', fontsize=12, fontweight='bold', color='black')\n",
    "    fig.text(0.5, -0.05, \"🟥 Red = Stop     🟩 Green = Go     ⏱ = Countdown     +1 = Vehicle Passed\", ha='center', fontsize=9, color='black', bbox=dict(facecolor='white', edgecolor='gray', boxstyle='round,pad=0.4'))\n",
    "    return fig\n",
    "\n",
    "# This function simulates the traffic flow over a series of steps for all intersections,\n",
    "# showing a real-time update of the environment using the learned Q-table.\n",
    "def demo_agents(q_tables, steps=30, speed=0.4):\n",
    "    inflow_probs = np.linspace(0.3, 0.7, len(q_tables))\n",
    "    envs = [TrafficIntersection(inflow_prob=prob) for prob in inflow_probs]\n",
    "    states = [get_discrete_state(env.reset()) for env in envs]\n",
    "    placeholders = [st.empty() for _ in q_tables]\n",
    "    intersection_states = [{\"action\": 0, \"timer\": 3} for _ in q_tables]\n",
    "\n",
    "    for t in range(steps):\n",
    "        for i, (env, q_table) in enumerate(zip(envs, q_tables)):\n",
    "            if intersection_states[i][\"timer\"] == 0:\n",
    "                intersection_states[i][\"action\"] = 1 - intersection_states[i][\"action\"]\n",
    "                intersection_states[i][\"timer\"] = 3\n",
    "            action = intersection_states[i][\"action\"]\n",
    "            intersection_states[i][\"timer\"] -= 1\n",
    "            full_state, _, cleared = env.step(action)\n",
    "            fig = draw_intersection(full_state, action, t, i, intersection_states[i][\"timer\"] + 1, highlight_clear=cleared)\n",
    "            placeholders[i].pyplot(fig)\n",
    "            plt.close(fig)\n",
    "            states[i] = get_discrete_state(full_state)\n",
    "        time.sleep(speed)\n",
    "\n",
    "    st.subheader(\"🚗 Total Vehicles Cleared per Intersection\")\n",
    "    for i, env in enumerate(envs):\n",
    "        st.markdown(f\"**Intersection {i+1}:** {env.total_cleared} vehicles\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d46f524",
   "metadata": {},
   "source": [
    "#### Streamlit UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b100a01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 17:02:07.479 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:07.480 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:07.481 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:07.482 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:07.483 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:07.483 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:07.484 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:07.484 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:07.485 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:07.486 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:07.487 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:07.487 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:07.488 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:07.488 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:07.489 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:07.489 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:07.490 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:07.490 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:07.491 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:07.492 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:10.595 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:10.596 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:10.598 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:10.599 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:10.644 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:10.645 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:10.646 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:10.646 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:10.690 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-10 17:02:10.691 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Streamlit UI ---------------- #\n",
    "st.title(\"Multi-Intersection Traffic Light Optimization (Q-learning)\")\n",
    "\n",
    "mode = st.selectbox(\"Choose Mode\", [\"Train Agent\", \"Demo Agent\"])\n",
    "n_intersections = st.slider(\"Number of Intersections\", 1, 4, 2)\n",
    "speed = st.slider(\"Demo Speed (sec/frame)\", 0.1, 1.0, 0.4)\n",
    "\n",
    "q_file = f\"q_tables_{n_intersections}.pkl\"\n",
    "\n",
    "if mode == \"Train Agent\":\n",
    "    st.info(\"Training Q-learning agents...\")\n",
    "    q_tables, rewards_list = train_agents(n_intersections)\n",
    "    st.success(\"Training complete!\")\n",
    "    with open(q_file, \"wb\") as f:\n",
    "        pickle.dump(q_tables, f)\n",
    "    for i, rewards in enumerate(rewards_list):\n",
    "        st.subheader(f\"Intersection {i+1}\")\n",
    "        st.line_chart(rewards)\n",
    "\n",
    "elif mode == \"Demo Agent\":\n",
    "    if os.path.exists(q_file):\n",
    "        with open(q_file, \"rb\") as f:\n",
    "            q_tables = pickle.load(f)\n",
    "        st.success(\"Loaded trained Q-tables.\")\n",
    "        demo_agents(q_tables, steps=30, speed=speed)\n",
    "    else:\n",
    "        st.error(\"No Q-tables found. Please train the agent(s) first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c50203",
   "metadata": {},
   "source": [
    "#### Simulation : Run command in terminal\n",
    "\n",
    "```streamlit run \"multi_intersection_sim.py\"```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvCSCN8020",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
